import os
import openai
import glob
import shutil

import numpy as np
import pandas as pd

import json
import io
import inspect
import requests
import re
import random
import string
import base64

from bs4 import BeautifulSoup
import dateutil.parser as parser
import tiktoken
from lxml import etree

import sys
from dotenv import load_dotenv
from openai import OpenAI

import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns

load_dotenv()
python_inter_args = '{"py_code": "import numpy as np\\narr = np.array([1, 2, 3, 4])\\nsum_arr = np.sum(arr)\\nsum_arr"}'

# å·¥å…·å®šä¹‰
python_inter_tool = {
    "type": "function",
    "function": {
        "name": "python_inter",
        "description": f"å½“ç”¨æˆ·éœ€è¦ç¼–å†™Pythonç¨‹åºå¹¶æ‰§è¡Œæ—¶ï¼Œè¯·è°ƒç”¨è¯¥å‡½æ•°ã€‚è¯¥å‡½æ•°å¯ä»¥æ‰§è¡Œä¸€æ®µPythonä»£ç å¹¶è¿”å›æœ€ç»ˆç»“æœï¼Œéœ€è¦æ³¨æ„ï¼Œæœ¬å‡½æ•°åªèƒ½æ‰§è¡Œéç»˜å›¾ç±»çš„ä»£ç ï¼Œè‹¥æ˜¯ç»˜å›¾ç›¸å…³ä»£ç ï¼Œåˆ™éœ€è¦è°ƒç”¨fig_interå‡½æ•°è¿è¡Œã€‚\nåŒæ—¶éœ€è¦æ³¨æ„ï¼Œç¼–å†™å¤–éƒ¨å‡½æ•°çš„å‚æ•°æ¶ˆæ¯æ—¶ï¼Œå¿…é¡»æ˜¯æ»¡è¶³jsonæ ¼å¼çš„å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚å¦‚ä»¥ä¸‹å½¢å¼å­—ç¬¦ä¸²å°±æ˜¯åˆè§„å­—ç¬¦ä¸²ï¼š{python_inter_args}",
        "parameters": {
            "type": "object",
            "properties": {
                "py_code": {
                    "type": "string",
                    "description": "The Python code to execute."
                },
                "g": {
                    "type": "string",
                    "description": "Global environment variables, default to globals().",
                    "default": "globals()"
                }
            },
            "required": ["py_code"]
        }
    }
} 

fig_inter_tool = {
    "type": "function",
    "function": {
        "name": "fig_inter",
        "description": (
            "å½“ç”¨æˆ·éœ€è¦ä½¿ç”¨ Python è¿›è¡Œå¯è§†åŒ–ç»˜å›¾ä»»åŠ¡æ—¶ï¼Œè¯·è°ƒç”¨è¯¥å‡½æ•°ã€‚"
            "è¯¥å‡½æ•°ä¼šæ‰§è¡Œç”¨æˆ·æä¾›çš„ Python ç»˜å›¾ä»£ç ï¼Œå¹¶è‡ªåŠ¨å°†ç”Ÿæˆçš„å›¾åƒå¯¹è±¡ä¿å­˜ä¸ºå›¾ç‰‡æ–‡ä»¶å¹¶å±•ç¤ºã€‚\n\n"
            "è°ƒç”¨è¯¥å‡½æ•°æ—¶ï¼Œè¯·ä¼ å…¥ä»¥ä¸‹å‚æ•°ï¼š\n\n"
            "1. `py_code`: ä¸€ä¸ªå­—ç¬¦ä¸²å½¢å¼çš„ Python ç»˜å›¾ä»£ç ï¼Œ**å¿…é¡»æ˜¯å®Œæ•´ã€å¯ç‹¬ç«‹è¿è¡Œçš„è„šæœ¬**ï¼Œ"
            "ä»£ç å¿…é¡»åˆ›å»ºå¹¶è¿”å›ä¸€ä¸ªå‘½åä¸º `fname` çš„ matplotlib å›¾åƒå¯¹è±¡ï¼›\n"
            "2. `fname`: å›¾åƒå¯¹è±¡çš„å˜é‡åï¼ˆå­—ç¬¦ä¸²å½¢å¼ï¼‰ï¼Œä¾‹å¦‚ 'fig'ï¼›\n"
            "3. `g`: å…¨å±€å˜é‡ç¯å¢ƒï¼Œé»˜è®¤ä¿æŒä¸º 'globals()' å³å¯ã€‚\n\n"
            "ğŸ“Œ è¯·ç¡®ä¿ç»˜å›¾ä»£ç æ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š\n"
            "- åŒ…å«æ‰€æœ‰å¿…è¦çš„ importï¼ˆå¦‚ `import matplotlib.pyplot as plt`, `import seaborn as sns` ç­‰ï¼‰ï¼›\n"
            "- å¿…é¡»åŒ…å«æ•°æ®å®šä¹‰ï¼ˆå¦‚ `df = pd.DataFrame(...)`ï¼‰ï¼Œä¸è¦ä¾èµ–å¤–éƒ¨å˜é‡ï¼›\n"
            "- æ¨èä½¿ç”¨ `fig, ax = plt.subplots()` æ˜¾å¼åˆ›å»ºå›¾åƒï¼›\n"
            "- ä½¿ç”¨ `ax` å¯¹è±¡è¿›è¡Œç»˜å›¾æ“ä½œï¼ˆä¾‹å¦‚ï¼š`sns.lineplot(..., ax=ax)`ï¼‰ï¼›\n"
            "- æœ€åæ˜ç¡®å°†å›¾åƒå¯¹è±¡ä¿å­˜ä¸º `fname` å˜é‡ï¼ˆå¦‚ `fig = plt.gcf()`ï¼‰ã€‚\n\n"
            "ğŸ“Œ ä¸éœ€è¦è‡ªå·±ä¿å­˜å›¾åƒï¼Œå‡½æ•°ä¼šè‡ªåŠ¨ä¿å­˜å¹¶å±•ç¤ºã€‚\n\n"
            "âœ… åˆè§„ç¤ºä¾‹ä»£ç ï¼š\n"
            "```python\n"
            "import matplotlib.pyplot as plt\n"
            "import seaborn as sns\n"
            "import pandas as pd\n\n"
            "df = pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6]})\n"
            "fig, ax = plt.subplots()\n"
            "sns.lineplot(data=df, x='x', y='y', ax=ax)\n"
            "ax.set_title('Line Plot')\n"
            "fig = plt.gcf()  # ä¸€å®šè¦èµ‹å€¼ç»™ fname æŒ‡å®šçš„å˜é‡å\n"
            "```"
        ),
        "parameters": {
            "type": "object",
            "properties": {
                "py_code": {
                    "type": "string",
                    "description": (
                        "éœ€è¦æ‰§è¡Œçš„ Python ç»˜å›¾ä»£ç ï¼ˆå­—ç¬¦ä¸²å½¢å¼ï¼‰ã€‚"
                        "ä»£ç å¿…é¡»åˆ›å»ºä¸€ä¸ª matplotlib å›¾åƒå¯¹è±¡ï¼Œå¹¶èµ‹å€¼ä¸º `fname` æ‰€æŒ‡å®šçš„å˜é‡åã€‚"
                    )
                },
                "fname": {
                    "type": "string",
                    "description": "å›¾åƒå¯¹è±¡çš„å˜é‡åï¼ˆä¾‹å¦‚ 'fig'ï¼‰ï¼Œä»£ç ä¸­å¿…é¡»ä½¿ç”¨è¿™ä¸ªå˜é‡åä¿å­˜ç»˜å›¾å¯¹è±¡ã€‚"
                },
                "g": {
                    "type": "string",
                    "description": "è¿è¡Œç¯å¢ƒå˜é‡ï¼Œé»˜è®¤ä¿æŒä¸º 'globals()' å³å¯ã€‚",
                    "default": "globals()"
                }
            },
            "required": ["py_code", "fname"]
        }
    }
}

get_answer_tool = {
    "type": "function",
    "function": {
        "name": "get_answer",
        "description": (
            "è”ç½‘æœç´¢å·¥å…·ï¼Œå½“ç”¨æˆ·æå‡ºçš„é—®é¢˜è¶…å‡ºä½ çš„çŸ¥è¯†åº“èŒƒç•´æ—¶ï¼Œæˆ–è¯¥é—®é¢˜ä½ ä¸çŸ¥é“ç­”æ¡ˆçš„æ—¶å€™ï¼Œè¯·è°ƒç”¨è¯¥å‡½æ•°æ¥è·å¾—é—®é¢˜çš„ç­”æ¡ˆã€‚è¯¥å‡½æ•°ä¼šè‡ªåŠ¨ä»çŸ¥ä¹ä¸Šæœç´¢å¾—åˆ°é—®é¢˜ç›¸å…³æ–‡æœ¬ï¼Œè€Œåä½ å¯å›´ç»•æ–‡æœ¬å†…å®¹è¿›è¡Œæ€»ç»“ï¼Œå¹¶å›ç­”ç”¨æˆ·æé—®ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå½“ç”¨æˆ·ç‚¹åè¦æ±‚æƒ³è¦äº†è§£GitHubä¸Šçš„é¡¹ç›®æ—¶å€™ï¼Œè¯·è°ƒç”¨get_answer_githubå‡½æ•°ã€‚"
        ),
        "parameters": {
            "type": "object",
            "properties": {
                "q": {
                    "type": "string",
                    "description": "ä¸€ä¸ªæ»¡è¶³çŸ¥ä¹æœç´¢æ ¼å¼çš„é—®é¢˜ï¼Œç”¨å­—ç¬¦ä¸²å½¢å¼è¿›è¡Œè¡¨ç¤ºã€‚",
                    "example": "ä»€ä¹ˆæ˜¯MCP?"
                },
                "g": {
                    "type": "string",
                    "description": "Global environment variables, default to globals().",
                    "default": "globals()"
                }
            },
            "required": ["q"]
        }
    }
}
# å·¥å…·å‡½æ•°
def python_inter(py_code, g='globals()'):
    """
    ä¸“é—¨ç”¨äºæ‰§è¡Œpythonä»£ç ï¼Œå¹¶è·å–æœ€ç»ˆæŸ¥è¯¢æˆ–å¤„ç†ç»“æœã€‚
    :param py_code: å­—ç¬¦ä¸²å½¢å¼çš„Pythonä»£ç ï¼Œ
    :param g: gï¼Œå­—ç¬¦ä¸²å½¢å¼å˜é‡ï¼Œè¡¨ç¤ºç¯å¢ƒå˜é‡ï¼Œæ— éœ€è®¾ç½®ï¼Œä¿æŒé»˜è®¤å‚æ•°å³å¯
    :returnï¼šä»£ç è¿è¡Œçš„æœ€ç»ˆç»“æœ
    """    
    print("æ­£åœ¨è°ƒç”¨python_interå·¥å…·è¿è¡ŒPythonä»£ç ...")
    try:
        return str(eval(py_code, g))
    except Exception as e:
        global_vars_before = set(g.keys())
        try:            
            exec(py_code, g)
        except Exception as e:
            return f"ä»£ç æ‰§è¡Œæ—¶æŠ¥é”™{e}"
        global_vars_after = set(g.keys())
        new_vars = global_vars_after - global_vars_before
        if new_vars:
            result = {var: g[var] for var in new_vars}
            print("ä»£ç å·²é¡ºåˆ©æ‰§è¡Œï¼Œæ­£åœ¨è¿›è¡Œç»“æœæ¢³ç†...")
            return str(result)
        else:
            print("ä»£ç å·²é¡ºåˆ©æ‰§è¡Œï¼Œæ­£åœ¨è¿›è¡Œç»“æœæ¢³ç†...")
            return "å·²ç»é¡ºåˆ©æ‰§è¡Œä»£ç "

def fig_inter(py_code, fname, g='globals()'):
    print("æ­£åœ¨è°ƒç”¨fig_interå·¥å…·è¿è¡ŒPythonä»£ç ...")
    import matplotlib
    import os
    import matplotlib.pyplot as plt
    import seaborn as sns
    import pandas as pd

    # åˆ‡æ¢ä¸ºæ— äº¤äº’å¼åç«¯
    current_backend = matplotlib.get_backend()
    matplotlib.use('Agg')

    # ç”¨äºæ‰§è¡Œä»£ç çš„æœ¬åœ°å˜é‡
    local_vars = {"plt": plt, "pd": pd, "sns": sns}

    # ç›¸å¯¹è·¯å¾„ä¿å­˜ç›®å½•
    pics_dir = 'data/pics'
    if not os.path.exists(pics_dir):
        os.makedirs(pics_dir)

    try:
        # æ‰§è¡Œç”¨æˆ·ä»£ç 
        exec(py_code, g, local_vars)
        g.update(local_vars)

        # è·å–å›¾åƒå¯¹è±¡
        fig = local_vars.get(fname, None)
        print(fig)
        if fig:
            rel_path = os.path.join(pics_dir, f"{fname}.png")
            fig.savefig(rel_path, bbox_inches='tight')
            print("ä»£ç å·²é¡ºåˆ©æ‰§è¡Œï¼Œæ­£åœ¨è¿›è¡Œç»“æœæ¢³ç†...")
            return f"âœ… å›¾ç‰‡å·²ä¿å­˜ï¼Œç›¸å¯¹è·¯å¾„: {rel_path}"
        else:
            return "âš ï¸ ä»£ç æ‰§è¡ŒæˆåŠŸï¼Œä½†æœªæ‰¾åˆ°å›¾åƒå¯¹è±¡ï¼Œè¯·ç¡®ä¿æœ‰ `fig = ...`ã€‚"
    except Exception as e:
        return f"âŒ æ‰§è¡Œå¤±è´¥ï¼š{e}"
    finally:
        # æ¢å¤åŸæœ‰ç»˜å›¾åç«¯
        matplotlib.use(current_backend)

def google_search(query, num_results=10, site_url=None):
    
    api_key = os.getenv("GOOGLE_SEARCH_API_KEY")
    cse_id = os.getenv("CSE_ID")
    print("Google API key:", api_key, "CSE ID:", cse_id)
    url = "https://www.googleapis.com/customsearch/v1"

    # API è¯·æ±‚å‚æ•°
    if site_url == None:
        params = {
        'q': query,          
        'key': api_key,      
        'cx': cse_id,        
        'num': num_results   
        }
    else:
        params = {
        'q': query,         
        'key': api_key,      
        'cx': cse_id,        
        'num': num_results,  
        'siteSearch': site_url
        }

    # å‘é€è¯·æ±‚
    response = requests.get(url, params=params)
    response.raise_for_status()

    # è§£æå“åº”
    search_results = response.json().get('items', [])

    # æå–æ‰€éœ€ä¿¡æ¯
    results = [{
        'title': item['title'],
        'link': item['link'],
        'snippet': item['snippet']
    } for item in search_results]

    return results

def windows_compatible_name(s, max_length=255):
    """
    å°†å­—ç¬¦ä¸²è½¬åŒ–ä¸ºç¬¦åˆWindowsæ–‡ä»¶/æ–‡ä»¶å¤¹å‘½åè§„èŒƒçš„åç§°ã€‚
    
    å‚æ•°:
    - s (str): è¾“å…¥çš„å­—ç¬¦ä¸²ã€‚
    - max_length (int): è¾“å‡ºå­—ç¬¦ä¸²çš„æœ€å¤§é•¿åº¦ï¼Œé»˜è®¤ä¸º255ã€‚
    
    è¿”å›:
    - str: ä¸€ä¸ªå¯ä»¥å®‰å…¨ç”¨ä½œWindowsæ–‡ä»¶/æ–‡ä»¶å¤¹åç§°çš„å­—ç¬¦ä¸²ã€‚
    """

    # Windowsæ–‡ä»¶/æ–‡ä»¶å¤¹åç§°ä¸­ä¸å…è®¸çš„å­—ç¬¦åˆ—è¡¨
    forbidden_chars = ['<', '>', ':', '"', '/', '\\', '|', '?', '*']

    # ä½¿ç”¨ä¸‹åˆ’çº¿æ›¿æ¢ä¸å…è®¸çš„å­—ç¬¦
    for char in forbidden_chars:
        s = s.replace(char, '_')

    # åˆ é™¤å°¾éƒ¨çš„ç©ºæ ¼æˆ–ç‚¹
    s = s.rstrip(' .')

    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä»¥ä¸‹ä¸å…è®¸è¢«ç”¨äºæ–‡æ¡£åç§°çš„å…³é”®è¯ï¼Œå¦‚æœæœ‰çš„è¯åˆ™æ›¿æ¢ä¸ºä¸‹åˆ’çº¿
    reserved_names = ["CON", "PRN", "AUX", "NUL", "COM1", "COM2", "COM3", "COM4", "COM5", "COM6", "COM7", "COM8", "COM9", 
                      "LPT1", "LPT2", "LPT3", "LPT4", "LPT5", "LPT6", "LPT7", "LPT8", "LPT9"]
    if s.upper() in reserved_names:
        s += '_'

    # å¦‚æœå­—ç¬¦ä¸²è¿‡é•¿ï¼Œè¿›è¡Œæˆªæ–­
    if len(s) > max_length:
        s = s[:max_length]

    return s

def get_search_text(q, url):
    cookie = os.getenv('search_cookie')
    user_agent = os.getenv('search_ueser_agent')

    code_ = False
    headers = {
        'authority': 'www.zhihu.com',
        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
        'accept-language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'cache-control': 'max-age=0',
        'cookie': cookie,
        'upgrade-insecure-requests': '1',
        'user-agent':user_agent,
    }

    # æ™®é€šé—®ç­”åœ°å€
    if 'zhihu.com/question' in url:
        res = requests.get(url, headers=headers).text
        res_xpath = etree.HTML(res)
        title = res_xpath.xpath('//div/div[1]/div/h1/text()')[0]
        text_d_elements = res_xpath.xpath('//div[contains(@class, "RichText")]//p/text()') # æ›¿æ¢ä¸ºæµ‹è¯•æœ‰æ•ˆçš„XPath
        if text_d_elements:
            text_d = text_d_elements
        else:
            print(f"Warning: Could not find main text for URL: {url}. Check XPath for text_d.")
            text_d = [] # ç¡®ä¿ text_d ä»ç„¶æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå³ä½¿æ˜¯ç©ºçš„ï¼Œä»¥ä¾¿åç»­å¾ªç¯ä¸ä¼šæŠ¥é”™
    
    # ä¸“æ åœ°å€
    elif 'zhuanlan' in url:
        headers['authority'] = 'zhuanlan.zhihu.com'
        res = requests.get(url, headers=headers).text
        res_xpath = etree.HTML(res)
        title_elements = res_xpath.xpath('//h1[contains(@class, "Post-Title")]/text()')
        if title_elements:
            title = title_elements[0]
        else:
            # å¤„ç†æœªæ‰¾åˆ°æ ‡é¢˜çš„æƒ…å†µï¼Œä¾‹å¦‚æ‰“å°è­¦å‘Šï¼Œæˆ–è€…è®¾ç½® title ä¸º None
            print(f"Warning: Could not find title for URL: {url}. HTML structure might have changed.")
            title = None # æˆ–è€… raise Exception("Title not found")
        #title = res_xpath.xpath('//div[1]/div/main/div/article/header/h1/text()')[0]
        text_d_elements = res_xpath.xpath('//div[contains(@class, "RichText")]//p/text()') # æ›¿æ¢ä¸ºæµ‹è¯•æœ‰æ•ˆçš„XPath
        if text_d_elements:
            text_d = text_d_elements
        else:
            print(f"Warning: Could not find main text for URL: {url}. Check XPath for text_d.")
            text_d = [] # ç¡®ä¿ text_d ä»ç„¶æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå³ä½¿æ˜¯ç©ºçš„ï¼Œä»¥ä¾¿åç»­å¾ªç¯ä¸ä¼šæŠ¥é”™

        code_elements = res_xpath.xpath('//div/main/div/article/div[1]/div/div/div//pre/code/text()')
        if code_elements:
            code_ = code_elements
        else:
            code_ = [] # åŒæ ·ç¡®ä¿ code_ æ˜¯åˆ—è¡¨
            
    # ç‰¹å®šå›ç­”çš„é—®ç­”ç½‘å€
    elif 'answer' in url:
        res = requests.get(url, headers=headers).text
        res_xpath = etree.HTML(res)
        title = res_xpath.xpath('//div/div[1]/div/h1/text()')[0]
        text_d_elements = res_xpath.xpath('//div[contains(@class, "RichText")]//p/text()') # æ›¿æ¢ä¸ºæµ‹è¯•æœ‰æ•ˆçš„XPath
        if text_d_elements:
            text_d = text_d_elements
        else:
            print(f"Warning: Could not find main text for URL: {url}. Check XPath for text_d.")
            text_d = [] # ç¡®ä¿ text_d ä»ç„¶æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå³ä½¿æ˜¯ç©ºçš„ï¼Œä»¥ä¾¿åç»­å¾ªç¯ä¸ä¼šæŠ¥é”™

    if title == None:
        return None
    
    else:
        title = windows_compatible_name(title)

        # åˆ›å»ºé—®é¢˜ç­”æ¡ˆæ­£æ–‡
        text = ''
        for t in text_d:
            txt = str(t).replace('\n', ' ')
            text += txt

        # å¦‚æœæœ‰codeï¼Œåˆ™å°†codeè¿½åŠ åˆ°æ­£æ–‡çš„è¿½åé¢
        if code_:
            for c in code_:
                co = str(c).replace('\n', ' ')    
                text += co

        encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")     
        json_data = [
            {
                "link": url,
                "title": title,
                "content": text,
                "tokens": len(encoding.encode(text))
            }
        ]
        
        # è‡ªåŠ¨åˆ›å»ºç›®å½•ï¼Œå¦‚æœä¸å­˜åœ¨çš„è¯
        dir_path = f'./data/auto_search/{q}'
        os.makedirs(dir_path, exist_ok=True)
    
        with open('./data/auto_search/%s/%s.json' % (q, title), 'w') as f:
            json.dump(json_data, f)

        return title
    
def get_answer(q, g='globals()'):
    """
    å½“ä½ æ— æ³•å›ç­”æŸä¸ªé—®é¢˜æ—¶ï¼Œè°ƒç”¨è¯¥å‡½æ•°ï¼Œèƒ½å¤Ÿè·å¾—ç­”æ¡ˆ
    :param q: å¿…é€‰å‚æ•°ï¼Œè¯¢é—®çš„é—®é¢˜ï¼Œå­—ç¬¦ä¸²ç±»å‹å¯¹è±¡
    :param g: gï¼Œå­—ç¬¦ä¸²å½¢å¼å˜é‡ï¼Œè¡¨ç¤ºç¯å¢ƒå˜é‡ï¼Œæ— éœ€è®¾ç½®ï¼Œä¿æŒé»˜è®¤å‚æ•°å³å¯
    :returnï¼šæŸé—®é¢˜çš„ç­”æ¡ˆï¼Œä»¥å­—ç¬¦ä¸²å½¢å¼å‘ˆç°
    """
    # é»˜è®¤æœç´¢è¿”å›5ä¸ªç­”æ¡ˆ
    print('æ­£åœ¨æ¥å…¥è°·æ­Œæœç´¢ï¼ŒæŸ¥æ‰¾å’Œé—®é¢˜ç›¸å…³çš„ç­”æ¡ˆ...')
    results = google_search(query=q, num_results=5, site_url='https://zhihu.com/')
    
    # åˆ›å»ºå¯¹åº”é—®é¢˜çš„å­æ–‡ä»¶å¤¹
    folder_path = './data/auto_search/%s' % q
    if not os.path.exists(folder_path):
        os.makedirs(folder_path)
    
    # å•ç‹¬æå–linksæ”¾åœ¨ä¸€ä¸ªlistä¸­
    num_tokens = 0
    content = ''
    for item in results:
        url = item['link']
        print('æ­£åœ¨æ£€ç´¢ï¼š%s' % url)
        title = get_search_text(q, url)
        with open('./data/auto_search/%s/%s.json' % (q, title), 'r') as f:
            jd = json.load(f)
        num_tokens += jd[0]['tokens']
        if num_tokens <= 12000:
            # print(jd[0]['content'])
            content += jd[0]['content']
        else:
            break
    return(content)

def print_code_if_exists(function_args):
    """
    å¦‚æœå­˜åœ¨ä»£ç ç‰‡æ®µï¼Œåˆ™æ‰“å°ä»£ç 
    """
    if function_args.get('py_code'):
        code = function_args['py_code']
        print("å³å°†æ‰§è¡Œä»¥ä¸‹ä»£ç ï¼š")
        print(code)
        
if __name__ == "__main__":
    #test_python_inter()
    #test_fig_inter()
    url = 'https://www.zhihu.com/question/7762420288'
    q = "ä»€ä¹ˆæ˜¯MCP"
    print(get_answer(q))